The motion for today's debate is that we should ban full body scanners.
Two main areas of clash: first on why it is rights violative.
Recognize that privacy rights are something that have been given to us first by the constitution of the government but also just based on the way that society appreciates itself and every individual within it.
Let's talk about the constitution first.
Recognize that the constitution, like any other like binding piece of paper, represents a contract between the individuals and the government.
And when the government fails to uphold this contract it violates the rules of that contract and fails to fulfill a like fundamental job that it has.
Like recognize that what the constitution is is a like statement on the part of the government: " here the rights that you have and that I am sworn to protect in exchange to be able to limit some of your rights, like your ability to be mobile.
And and some of your like some of your more broad like privacy rights.
Like the ability to monitor you in some records. "
But at the end of the day once it stops doing so, the government stops fulfilling those like basic needs.
Right?
Like recognize that the pragmatics don't matter insofar as the good is idiosyncratic.
And the only way that we can legislate that got on the part of the government is through a document that everybody has agreed to as being the most fundamental to not, to protecting the other things that we see as good.
This is why we have things like protections of freedom of religion.
Because it is true that there is never going to be a world in which we see every individual's religion as the same.
And there's never going to be a world in which I value someone else's religion to the same extent as mine.
But what the government can do is preserve everybody's abilities to define that good through something like freedom of religion.
We also just think that predictability on the part of the government is incredibly important.
If the government says that you have this like right and then two days later takes it away without informing anybody, then it necessarily means that people cannot predict the actions of the government and cannot predict their own rights and safety.
We think this is incredibly important insofar as the way in which people trust the government is based in their prediction of the government's actions and in their predictions that the government will act in the way that are best for them.
We also think that it's important in terms of preventing over scrutiny of the government.
Recognize that bodies are very intimate and very personal, and massively part of the way that we self actualize and relate to the world insofar as our physical presentation is within our bodies, even if we might interact with each other on some deeper level.
So as the tool through which we communicate to the world bodies therefore retain some rights in terms of the way that we self actualize within them.
We think that if I am someone who is like overweight and wants to hide that, then it is important that my right to like to not be seen through a screen by personal strangers, by like random strangers, is something that ought to be preserved and something that is incredibly important.
But our second area of clash is just on why these things are entirely useless.
Recognize that there have been tons of security tests that have shown that professionals can get past these kinds of machines with no problem by changing the material that they build their weapons out of and by hiding them in the correct places.
The problem with continuing to use a piece of machinery that is so bad is that it creates a false sense of solvency.
It means that we stop innovating and finding new ways to ensure security because we think that it has already been solved.
This means we provide an opening to criminals that is incredibly consistent and readily exploited that we will never end.
Criminals know they can rely on it therefore can use at their whim.
It also means that when something does go wrong no one blames the technology because humans inherently tend to trust technology more than they trust individual error.
So rather than attributing any kind of problem to the tech, they're going to say: " no, look, these are the people who are manning the machines at that time and this is why they are the ones who are actually to blame.
We think this is really bad first because it puts those people's jobs at risk.
If I am the TSA agent who just arbitrarily happens to be running that booth at the time at which a breach happens, I probably shouldn't lose my job it's not my fault that the breach happened.
But it also means that we're never going to change the tech, only changing the people, which means you never solve the fundamental problem.
For these reasons, proud to propose.